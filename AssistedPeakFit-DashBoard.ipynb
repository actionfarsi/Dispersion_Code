{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy import average, hstack, argsort, ones, sort, diff, where\n",
    "\n",
    "from ipywidgets import widgets\n",
    "\n",
    "from itertools import cycle\n",
    "import lmfit\n",
    "from scipy.io import savemat, loadmat\n",
    "from matplotlib import pylab as pl\n",
    "import scipy.optimize as sciop\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage.measurements import label, find_objects, center_of_mass\n",
    "from scipy.ndimage.filters import sobel, gaussian_filter1d, median_filter, laplace\n",
    "from scipy.signal import find_peaks_cwt\n",
    "\n",
    "from scipy.interpolate import UnivariateSpline, interp1d\n",
    "\n",
    "import plotly\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot,iplot_mpl\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode()\n",
    "\n",
    "c_light = 3e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kippemberg paper\n",
    "[doi:10.1038/nphoton.2009.138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def get_peaks(t, c, min_dist = 0.0000035):\n",
    "    ## isolate each peak\n",
    "    #l, n = label(c)\n",
    "    #peaks = np.array([average(t[obj]) for obj in find_objects(l)])\n",
    "    #return peaks\n",
    "\n",
    "fit_max_f = lmfit.Model(lambda x, x0, a, g: a/(1+(x-x0)**2/(g)**2))\n",
    "\n",
    "def fit_max(x,y):\n",
    "    #fit_r = fit_max_f.fit(data=y, x = x, x0 = x[np.argmax(y)],\n",
    "      #                    a = np.amax(y), g = 100)\n",
    "    return x[np.argmax(y)]\n",
    "    return fit_r.params['x0'].value\n",
    "\n",
    "def LorentzianLin(m,b,amp,xc,gam,x):\n",
    "    outs=m*(x-xc)+b+(amp/(np.pi*2))/((x-xc)**2+(gam/2)**2)\n",
    "    return outs\n",
    "\n",
    "def Lorentzian(b,amp,xc,gam,x):\n",
    "    outs=b+(amp/(np.pi*2))/((x-xc)**2+(gam/2)**2)\n",
    "    return outs\n",
    "\n",
    "def Quadratic(a,b,c,x):\n",
    "    outs=a+b*x+c*x*x\n",
    "    return outs\n",
    "\n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or np.fabs(value - array[idx-1]) < np.fabs(value - array[idx])):\n",
    "        return idx-1\n",
    "    else:\n",
    "        return idx\n",
    "    \n",
    "def rollingWindow(a, window, edge = 'copy'):\n",
    "    if edge == 'copy':\n",
    "        extended = np.zeros(a.shape[:-1] + (a.shape[-1]+window-1, ))\n",
    "        extended[..., int(window/2.-1): -int(window/2.)] = a[...]\n",
    "        extended[..., :int(window/2.+1)]= a[...,0]\n",
    "        extended[..., -int(window/2.):]= a[...,-1]\n",
    "        a = extended\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "def rollingAverage(a,win_size=10):\n",
    "    out=average(rollingWindow(a, win_size), -1)\n",
    "    #out1=np.append(np.zeros(int(window/2)),out)\n",
    "    #out2=out1[:-int(window/2)] #these two modiciations make the filter symetric\n",
    "    return out\n",
    "\n",
    "import numpy as np\n",
    "def find_nearest_unsrt(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename='rb_1555_1570_200nm_1'\n",
    "#filename = 'test_pratham_1530_1600'\n",
    "#filename = 'scan_1530_1570_85sec_10_4_16'\n",
    "#filename = 'scan_1540_1570_85sec_10_4_16_agilent'\n",
    "#trans = loadmat('C:\\\\Users\\\\Rees\\\\Documents\\\\Dispersion Data\\\\'+filename+'_tr', squeeze_me = True)['data']\n",
    "trans = loadmat(filename+'_tr', squeeze_me = True)['data']\n",
    "ind = np.where(~np.isnan(trans[1]))[0]\n",
    "first, last = ind[0], ind[-1]\n",
    "trans[1][:first] = trans[1][first]\n",
    "trans[1][last + 1:] = trans[1][last]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## smooths, and removes a low-passed background, on a subset of data to test settings\n",
    "highpassbin=20000\n",
    "lowpassbin=400\n",
    "# testx=trans[0,100000:1000000]\n",
    "# testy=trans[1][100000:1000000]\n",
    "# trans_ptest = rollingAverage(testy,lowpassbin)-rollingAverage(testy,highpassbin)\n",
    "# trans_ptest = np.nan_to_num(trans_ptest)\n",
    "# f,ax = plt.subplots(1,1, figsize=(8,4))\n",
    "# ax.plot(testx, trans_ptest)\n",
    "# ax.plot(testx, testy-np.mean(testy))\n",
    "# iplot_mpl(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## smooths, and saves the full data set, to avoid having to filter it again\n",
    "trans_p = rollingAverage(trans[1],lowpassbin)-rollingAverage(trans[1],highpassbin)\n",
    "trans[1]=trans_p\n",
    "savemat(filename+'_tr'+'_filt', {'data': np.vstack([trans[0], trans[1]])}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Loads the smoothed dataset, to avoid re-filtering\n",
    "trans = loadmat(filename+'_tr_filt', squeeze_me = True)['data']\n",
    "ind = np.where(~np.isnan(trans[1]))[0]\n",
    "first, last = ind[0], ind[-1]\n",
    "trans[1][:first] = trans[1][first]\n",
    "trans[1][last + 1:] = trans[1][last]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plots the smoothed data, to enable manual peak identification\n",
    "f,ax = pl.subplots(1,1, figsize=(10,4))\n",
    "ax.set_xlim(0,1e7)\n",
    "line=ax.plot(trans[0,::25],trans[1,::25])\n",
    "iplot_mpl(f)\n",
    "savemat(filename+'_tr'+'_filtered_spectrum', {'peaks1':trans[0],'peaks2':trans[1]}),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the the plot above, to zoom into the first set of nice looking resonances you see. If you have multiple resonance you wish to track the format is\n",
    "\n",
    "ModePeak=[[Peak1(0),Peak1(1)],[Peak2(0),Peak2(1)],[...]]\n",
    "\n",
    "The program will then take these initial peaks, and hunt for the rest of the set of peaks based on the seperation of the initial peaks and their location. It does this by guessing where the next will be by extrapolating the previous few peaks, looking at \"fitsize\" points around the guess, and finding the minum value inside that small search window.\n",
    "\n",
    "Paramters to adjust are the \"fitsize\", and \"peakstofit\" which sets how many peaks it will look for in each mode family before it exits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ModePeak=[[.1420803,.2472956],[1,2]]\n",
    "\n",
    "ModePeak=np.multiply(ModePeak,1E6)\n",
    "fitsize=8000 #number of points around guess to fit\n",
    "modefamilias=1#number of distinct sets of peaks you want to fit\n",
    "peakstofit=20\n",
    "peaks=[[],[],[]]\n",
    "\n",
    "f,ax = pl.subplots(1,1, figsize=(10,4))\n",
    "for j in range(modefamilias):\n",
    "    modeselect=j\n",
    "    indexmin = find_nearest(trans[0],ModePeak[modeselect][0])\n",
    "    datx=trans[0][indexmin-fitsize:indexmin+fitsize]\n",
    "    daty=trans[1][indexmin-fitsize:indexmin+fitsize]                                                                                                        \n",
    "    start=datx[find_nearest_unsrt(daty,min(daty))]\n",
    "    PeakLoc=[start]\n",
    "    ax.plot(datx,daty)\n",
    "    gap=ModePeak[modeselect][1]-start\n",
    "    locguess=start+gap\n",
    "    indices=[]\n",
    "    for i in range(peakstofit):\n",
    "        indices.append(i)\n",
    "        indexmin = find_nearest(trans[0],locguess)\n",
    "        datx=trans[0][indexmin-fitsize:indexmin+fitsize]\n",
    "        daty=trans[1][indexmin-fitsize:indexmin+fitsize]\n",
    "        thismin=datx[find_nearest_unsrt(daty,min(daty))]\n",
    "        if i>10:\n",
    "            PeakLoc.append(thismin) \n",
    "            xdat=[0,1,2,3,4,5,6]\n",
    "            ydat=PeakLoc[-7:]\n",
    "            fits=np.poly1d(np.polyfit(xdat, ydat,2))\n",
    "            locguess= fits(7)\n",
    "        else:\n",
    "            gap=thismin-PeakLoc[-1]\n",
    "            PeakLoc.append(thismin) \n",
    "            locguess= thismin + gap\n",
    "        ax.plot(datx[::50],daty[::50])\n",
    "    peaks[j]=PeakLoc\n",
    "iplot_mpl(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can see how each fitted peak looks. You can use this to diagnoise issues, and see if \"fitsize\" is properly set.\n",
    "\n",
    "The next block, shows an example of the FSR versus frequency of the sweep to diagnose issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start=0\n",
    "cut=80\n",
    "fsr1=np.gradient(np.asarray(peaks[0][start:cut]))\n",
    "#fsr2=np.gradient(np.asarray(peaks[1][start:cut]))\n",
    "#fsr3=np.diff(np.asarray(peaks[2][start:cut]))\n",
    "\n",
    "f,ax = pl.subplots(1,1, figsize=(10,4))\n",
    "ax.plot(peaks[0][0:cut],fsr1)  \n",
    "#ax.plot(peaks[1][0:cut],fsr2)  \n",
    "#ax.plot(fsr3)\n",
    "iplot_mpl(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the locations of each of the fitted peaks. This needs to be modifed to reflect the number of mode families you fit\n",
    "{'peaks1':peaks[0]}->{'peaks1':peaks[0],'peaks2':peaks[1],.....}\n",
    "\n",
    "At this point, you will have the locations of many modes, and analysis is more convenient in a higher level programming language (aka MatLab)\n",
    "\n",
    "Issues the data may have, is 250 Mhz jumps when a comb tooth is missed, and if you see consistently grouped peaks, with a few discrete disagreements, its totally fair to artifically adjust the 'bad' points by discrete amounts.\n",
    "\n",
    "Typical performance as of 11/3/2016 is a 10 Mhz statistical uncertainty in fitted resonance locations, and an 8 Mhz statistical uncertainty in FSR, over a set of 10 measurements of the same chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Save transmission and frequency in one file\n",
    "savemat(filename+'_tr'+'_fsr', {'peaks1':peaks[0],'peaks2':peaks[1]}),\n",
    "                        #'options': dict(t_range = t_range,\n",
    "                        #                dem_th = dem_th,\n",
    "                        #                dem_alpha = dem_alpha,\n",
    "                        #                do_patch = do_patch,\n",
    "                        #                patch_pattern = patch_pattern)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is for '12_8_2016_Jae_doublering4_950_1400_200GHZ_XXX' data series\n",
    "#ModePeak=[[.1576652,.3851763],[.4093255,.6396964]] #bad data\n",
    "#ModePeak=[[.1661502,.3777254],[1.949471,2.159452]] #no second mode family\n",
    "#ModePeak=[[.1492225,.3608335],[.704079,.566845]]   #no secons mode family\n",
    "#ModePeak=[[.1969874,.4095016],[.21938,.4308126]]\n",
    "#ModePeak=[[.2075429,.4190832],[.4419086,.6528858]]\n",
    "#ModePeak=[[.1957864,.4073583],[.4448152,.6561047]]\n",
    "#ModePeak=[[.1683048,.3798743],[.704079,.566845]]   #no second mode family\n",
    "#ModePeak=[[.1786431,.3902426],[.21938,.4308126]]\n",
    "#ModePeak=[[.158146,.3697491],[.1668186,.3817283]]\n",
    "#ModePeak=[[.206704,.4182609],[.2153452,.4300555]]\n",
    "#ModePeak=[[.1643852,.3759786],[.1730335,.3878131]]\n",
    "#ModePeak=[[.3972519,.6085367],[.4132746,.6239653]]\n",
    "#odePeak=[[.01818814,.229771],[.03208237,.2433376]]\n",
    "#ModePeak=[[.194493309,.4060884],[.704079,.566845]]\n",
    "#ModePeak=[[.2018233,.4134242],[.704079,.566845]]\n",
    "\n",
    "\n",
    "# for the '1530_1610_r3_ctl_Hpol_11_12_2016_xxx' set of data\n",
    "#ModePeak=[[.030737,.1251096],[.4704079,.566845]]\n",
    "#ModePeak=[[.057018,.1514607],[.4704079,.566845]]\n",
    "#ModePeak=[[.06670165,.1611261],[.4704079,.566845]]\n",
    "#ModePeak=[[.0642822,.158566],[.4704079,.566845]]\n",
    "#ModePeak=[[.06211067,.1565112],[.4704079,.566845]]\n",
    "#ModePeak=[[.01329404,.1076933],[.4704079,.566845]]\n",
    "#ModePeak=[[.03531843,.12974],[.4704079,.566845]]\n",
    "#ModePeak=[[.0864544,.1808618],[.4704079,.566845]]\n",
    "\n",
    "# Enter two adjacent locations, for each identifiable mode [[a1,a2],[b1,b2],[c1,c2]]\n",
    "#ModePeak=[[2.315067,2.410103],[2.351455,2.445791],[2.355071,2.451556]] #pratham_2 initial guesses\n",
    "#ModePeak=[[.3384759,.4329465],[.3903086,.4867791]]#10_20_2016_Agilent_thermal_on_1530_1570_1 initial guess\n",
    "#ModePeak=[[.4106326,.5049396],[.4643857,.5608583]] #10_20_2016_Agilent_thermal_off_1530_1570_1 initial guess\n",
    "#ModePeak=[[.009349,.1038205],[.0547619,.1512781]] #10_20_2016_Agilent_thermal_off_1530_1570_2 initial guess\n",
    "#ModePeak=[[.3466385,.4411104],[.398475,.4949343]] #10_20_2016_Agilent_thermal_on_1530_1570_2 initial guess\n",
    "\n",
    "#ModePeak=[[.2082301,.3026331],[.2599713,.3564166]] #'10_25_2016_CTL_thermal_off_1530_1610_1'\n",
    "#ModePeak=[[.0446599,.1391195],[1,2]] #'10_25_2016_CTL_thermal_off_1530_1610_2'\n",
    "#ModePeak=[[.2010087,.295358],[1.60369,1.700163]] #'10_25_2016_CTL_thermal_off_1530_1610_3'\n",
    "#ModePeak=[[.03547385,.1298593],[1,2]]#'10_25_2016_CTL_thermal_off_1530_1610_4'\n",
    "#ModePeak = [[2.281411,2.376414],[1,2]] #'10_25_2016_CTL_thermal_off_1530_1610_5'\n",
    "\n",
    "#for the 10_27_2016_CTL_thermal_off_1530_1610 series of data, in order\n",
    "#ModePeak=[[.01278,.1070939],[1,2]]\n",
    "#ModePeak=[[.04172128,.136025],[1,2]]\n",
    "#ModePeak=[[.07201787,.1664154],[1,2]]\n",
    "#ModePeak=[[.02944836,.123748],[1,2]]\n",
    "#ModePeak=[[.07240215,.1667194],[1,2]]\n",
    "#ModePeak=[[.07012679,.1645023],[1,2]]\n",
    "#ModePeak=[[.037147,.131462],[1,2]]\n",
    "#ModePeak=[[.04735518,.141726],[1,2]]\n",
    "#ModePeak=[[.02382155,.1181836],[1,2]]\n",
    "#ModePeak=[[.0390736,.133407],[1,2]]\n",
    "\n",
    "#for the 10_27_2016_CTL_thermal_off_1530_1610 series of data, in order\n",
    "#ModePeak=[[.01278,.1070939],[.4441082,.5405605]]\n",
    "#ModePeak=[[.04172128,.136025],[.473012,.569514]]\n",
    "#ModePeak=[[.07201787,.1664154],[.4089817,.505475]]\n",
    "#ModePeak=[[.02944836,.123748],[.4607695,.5572036]]\n",
    "#ModePeak=[[.07240215,.1667194],[.4072247,.5037364]]\n",
    "#ModePeak=[[.07012679,.1645023],[.4049401,.5014603]]\n",
    "#ModePeak=[[.037147,.131462],[.4684524,.5649]]\n",
    "#ModePeak=[[.04735518,.141726],[.4786845,.5751437]]\n",
    "#ModePeak=[[.02382155,.1181836],[.4554438,.5518753]]\n",
    "#ModePeak=[[.0390736,.133407],[.4704079,.566845]]\n",
    "\n",
    "\n",
    "\n",
    "#for the 11_10_2016_CTL_1530_1610_ series of data, in collection order\n",
    "#ModePeak=[[.0945437,.2924154],[.4704079,.566845]]\n",
    "#ModePeak=[[.1800357,.3780944],[.4704079,.566845]]\n",
    "#ModePeak=[[.02699714,.2252697],[.4704079,.566845]]\n",
    "#ModePeak=[[.08198492,.2802272],[.4704079,.566845]] #Still bad for some reason\n",
    "#ModePeak=[[.04347161,.2417198],[.4704079,.566845]]\n",
    "#ModePeak=[[.0729834,.2712292],[.4704079,.566845]]\n",
    "#ModePeak=[[.1122395,.3105037],[.4704079,.566845]]\n",
    "#ModePeak=[[.06495976,.2632406],[.4704079,.566845]]\n",
    "#ModePeak=[[.02021572,.2184811],[.4704079,.566845]]\n",
    "#ModePeak=[[.1637376,.3615994],[.4704079,.566845]]\n",
    "\n",
    "# For the '11_29_2016_1530_1610_TE_' series of data, in collection order\n",
    "# This data is alex's chip, with TE polarization\n",
    "#ModePeak=[[.13051,.32875],[.4704079,.566845]]\n",
    "#ModePeak=[[.06997713,.2682505],[.4704079,.566845]]\n",
    "#ModePeak=[[.1172247,.3155148],[.4704079,.566845]]\n",
    "#ModePeak=[[.1902402,.3885278],[.4704079,.566845]]\n",
    "#ModePeak=[[.1267433,.3250211],[.4704079,.566845]]\n",
    "# This data is alex's chip, with TM polarization\n",
    "#ModePeak=[[.0335342,.230357],[.4704079,.566845]]\n",
    "\n",
    "# This data is alex's chip, with TE polarization looking at higher order Mode\n",
    "#ModePeak=[[1.102855,1.29276],[1.29276,.566845]]\n",
    "# This data is alex's chip, with TM polarization Looking at higher order Mode\n",
    "#ModePeak=[[1.20453,1.392146],[.4704079,.566845]]\n",
    "\n",
    "\n",
    "\n",
    "# This is for '12_8_2016_Pratham_1530_1570_TE_type2a4r4_1' data series\n",
    "#ModePeak=[[.2072209,.3007048],[.4093255,.6396964]] \n",
    "#ModePeak=[[.1640734,.2576819],[.4093255,.6396964]] \n",
    "#ModePeak=[[.05806241,.1515734],[.4093255,.6396964]] \n",
    "#ModePeak=[[.1393745,.232804],[.4093255,.6396964]] \n",
    "#ModePeak=[[.1228236,.2162741],[.4093255,.6396964]] \n",
    "\n",
    "# This is for '12_8_2016_Pratham_1530_1570_TE_type2a4r3_1' data series\n",
    "#ModePeak=[[.07815829,.1720419],[.09987,.1899297]] \n",
    "#ModePeak=[[.09451445,.1880102],[.1158486,.2058542]] \n",
    "#ModePeak=[[.05480697,.1474464],[.07941727,.1691536]] \n",
    "#ModePeak=[[.1086339,.2017672],[.1300376,.2199785]] \n",
    "#ModePeak=[[.03391709,.1274601],[.0557347,.1457869]] \n",
    "\n",
    "# This is for '12_8_2016_Pratham_1530_1570_TE_type2a4r1_1' data series\n",
    "#ModePeak=[[.2405592,.3303456],[.09987,.1899297]] \n",
    "#ModePeak=[[.0847509,.1745493],[.0557347,.1457869]] #is bad\n",
    "#ModePeak=[[.0847509,.1745493],[.0557347,.1457869]] \n",
    "#ModePeak=[[.05812133,.1480766],[.0557347,.1457869]] \n",
    "#ModePeak=[[.02275551,.1127163],[.0557347,.1457869]]\n",
    "#ModePeak=[[.04673739,.1366031],[.0557347,.1457869]] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Detect peaks in data based on their amplitude and other features.\"\"\"\n",
    "\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "\n",
    "__author__ = \"Marcos Duarte, https://github.com/demotu/BMC\"\n",
    "__version__ = \"1.0.4\"\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "\n",
    "def detect_peaks(x, mph=None, mpd=1, threshold=0, edge='rising',\n",
    "                 kpsh=False, valley=False, show=False, ax=None):\n",
    "\n",
    "    \"\"\"Detect peaks in data based on their amplitude and other features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1D array_like\n",
    "        data.\n",
    "    mph : {None, number}, optional (default = None)\n",
    "        detect peaks that are greater than minimum peak height.\n",
    "    mpd : positive integer, optional (default = 1)\n",
    "        detect peaks that are at least separated by minimum peak distance (in\n",
    "        number of data).\n",
    "    threshold : positive number, optional (default = 0)\n",
    "        detect peaks (valleys) that are greater (smaller) than `threshold`\n",
    "        in relation to their immediate neighbors.\n",
    "    edge : {None, 'rising', 'falling', 'both'}, optional (default = 'rising')\n",
    "        for a flat peak, keep only the rising edge ('rising'), only the\n",
    "        falling edge ('falling'), both edges ('both'), or don't detect a\n",
    "        flat peak (None).\n",
    "    kpsh : bool, optional (default = False)\n",
    "        keep peaks with same height even if they are closer than `mpd`.\n",
    "    valley : bool, optional (default = False)\n",
    "        if True (1), detect valleys (local minima) instead of peaks.\n",
    "    show : bool, optional (default = False)\n",
    "        if True (1), plot data in matplotlib figure.\n",
    "    ax : a matplotlib.axes.Axes instance, optional (default = None).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ind : 1D array_like\n",
    "        indeces of the peaks in `x`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The detection of valleys instead of peaks is performed internally by simply\n",
    "    negating the data: `ind_valleys = detect_peaks(-x)`\n",
    "    \n",
    "    The function can handle NaN's \n",
    "\n",
    "    See this IPython Notebook [1]_.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] http://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/DetectPeaks.ipynb\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from detect_peaks import detect_peaks\n",
    "    >>> x = np.random.randn(100)\n",
    "    >>> x[60:81] = np.nan\n",
    "    >>> # detect all peaks and plot data\n",
    "    >>> ind = detect_peaks(x, show=True)\n",
    "    >>> print(ind)\n",
    "\n",
    "    >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
    "    >>> # set minimum peak height = 0 and minimum peak distance = 20\n",
    "    >>> detect_peaks(x, mph=0, mpd=20, show=True)\n",
    "\n",
    "    >>> x = [0, 1, 0, 2, 0, 3, 0, 2, 0, 1, 0]\n",
    "    >>> # set minimum peak distance = 2\n",
    "    >>> detect_peaks(x, mpd=2, show=True)\n",
    "\n",
    "    >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
    "    >>> # detection of valleys instead of peaks\n",
    "    >>> detect_peaks(x, mph=0, mpd=20, valley=True, show=True)\n",
    "\n",
    "    >>> x = [0, 1, 1, 0, 1, 1, 0]\n",
    "    >>> # detect both edges\n",
    "    >>> detect_peaks(x, edge='both', show=True)\n",
    "\n",
    "    >>> x = [-2, 1, -2, 2, 1, 1, 3, 0]\n",
    "    >>> # set threshold = 2\n",
    "    >>> detect_peaks(x, threshold = 2, show=True)\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.atleast_1d(x).astype('float64')\n",
    "    if x.size < 3:\n",
    "        return np.array([], dtype=int)\n",
    "    if valley:\n",
    "        x = -x\n",
    "    # find indices of all peaks\n",
    "    dx = x[1:] - x[:-1]\n",
    "    # handle NaN's\n",
    "    indnan = np.where(np.isnan(x))[0]\n",
    "    if indnan.size:\n",
    "        x[indnan] = np.inf\n",
    "        dx[np.where(np.isnan(dx))[0]] = np.inf\n",
    "    ine, ire, ife = np.array([[], [], []], dtype=int)\n",
    "    if not edge:\n",
    "        ine = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "    else:\n",
    "        if edge.lower() in ['rising', 'both']:\n",
    "            ire = np.where((np.hstack((dx, 0)) <= 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "        if edge.lower() in ['falling', 'both']:\n",
    "            ife = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) >= 0))[0]\n",
    "    ind = np.unique(np.hstack((ine, ire, ife)))\n",
    "    # handle NaN's\n",
    "    if ind.size and indnan.size:\n",
    "        # NaN's and values close to NaN's cannot be peaks\n",
    "        ind = ind[np.in1d(ind, np.unique(np.hstack((indnan, indnan-1, indnan+1))), invert=True)]\n",
    "    # first and last values of x cannot be peaks\n",
    "    if ind.size and ind[0] == 0:\n",
    "        ind = ind[1:]\n",
    "    if ind.size and ind[-1] == x.size-1:\n",
    "        ind = ind[:-1]\n",
    "    # remove peaks < minimum peak height\n",
    "    if ind.size and mph is not None:\n",
    "        ind = ind[x[ind] >= mph]\n",
    "    # remove peaks - neighbors < threshold\n",
    "    if ind.size and threshold > 0:\n",
    "        dx = np.min(np.vstack([x[ind]-x[ind-1], x[ind]-x[ind+1]]), axis=0)\n",
    "        ind = np.delete(ind, np.where(dx < threshold)[0])\n",
    "    # detect small peaks closer than minimum peak distance\n",
    "    if ind.size and mpd > 1:\n",
    "        ind = ind[np.argsort(x[ind])][::-1]  # sort ind by peak height\n",
    "        idel = np.zeros(ind.size, dtype=bool)\n",
    "        for i in range(ind.size):\n",
    "            if not idel[i]:\n",
    "                # keep peaks with the same height if kpsh is True\n",
    "                idel = idel | (ind >= ind[i] - mpd) & (ind <= ind[i] + mpd) \\\n",
    "                    & (x[ind[i]] > x[ind] if kpsh else True)\n",
    "                idel[i] = 0  # Keep current peak\n",
    "        # remove the small peaks and sort back the indices by their occurrence\n",
    "        ind = np.sort(ind[~idel])\n",
    "\n",
    "    if show:\n",
    "        if indnan.size:\n",
    "            x[indnan] = np.nan\n",
    "        if valley:\n",
    "            x = -x\n",
    "        _plot(x, mph, mpd, threshold, edge, valley, ax, ind)\n",
    "\n",
    "    return ind\n",
    "\n",
    "def _plot(x, mph, mpd, threshold, edge, valley, ax, ind):\n",
    "    \"\"\"Plot results of the detect_peaks function, see its help.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except ImportError:\n",
    "        print('matplotlib is not available.')\n",
    "    else:\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "        ax.plot(x, 'b', lw=1)\n",
    "        if ind.size:\n",
    "            label = 'valley' if valley else 'peak'\n",
    "            label = label + 's' if ind.size > 1 else label\n",
    "            ax.plot(ind, x[ind], '+', mfc=None, mec='r', mew=2, ms=8,\n",
    "                    label='%d %s' % (ind.size, label))\n",
    "            ax.legend(loc='best', framealpha=.5, numpoints=1)\n",
    "        ax.set_xlim(-.02*x.size, x.size*1.02-1)\n",
    "        ymin, ymax = x[np.isfinite(x)].min(), x[np.isfinite(x)].max()\n",
    "        yrange = ymax - ymin if ymax > ymin else 1\n",
    "        ax.set_ylim(ymin - 0.1*yrange, ymax + 0.1*yrange)\n",
    "        ax.set_xlabel('Data #', fontsize=14)\n",
    "        ax.set_ylabel('Amplitude', fontsize=14)\n",
    "        mode = 'Valley detection' if valley else 'Peak detection'\n",
    "        ax.set_title(\"%s (mph=%s, mpd=%d, threshold=%s, edge='%s')\"\n",
    "                     % (mode, str(mph), mpd, str(threshold), edge))\n",
    "        # plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "def fit_max(x,y):\n",
    "    #fit_r = fit_max_f.fit(data=y, x = x, x0 = x[np.argmax(y)],\n",
    "      #                    a = np.amax(y), g = 100)\n",
    "    return x[np.argmax(y)]\n",
    "    return fit_r.params['x0'].value\n",
    "\n",
    "def LorentzianLin(m,b,amp,xc,gam,x):\n",
    "    outs=m*(x-xc)+b+(amp/(np.pi*2))/((x-xc)**2+(gam/2)**2)\n",
    "    return outs\n",
    "\n",
    "def Lorentzian(b,amp,xc,gam,x):\n",
    "    outs=b+(amp/(np.pi*2))/((x-xc)**2+(gam/2)**2)\n",
    "    return outs\n",
    "\n",
    "def Quadratic(a,b,c,x):\n",
    "    outs=a+b*x+c*x*x\n",
    "    return outs\n",
    "\n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or np.fabs(value - array[idx-1]) < np.fabs(value - array[idx])):\n",
    "        return idx-1\n",
    "    else:\n",
    "        return idx\n",
    "    \n",
    "def rollingWindow(a, window, edge = 'copy'):\n",
    "    if edge == 'copy':\n",
    "        extended = np.zeros(a.shape[:-1] + (a.shape[-1]+window-1, ))\n",
    "        extended[..., int(window/2.-1): -int(window/2.)] = a[...]\n",
    "        extended[..., :int(window/2.+1)]= a[...,0]\n",
    "        extended[..., -int(window/2.):]= a[...,-1]\n",
    "        a = extended\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "def rollingAverage(a,win_size=10):\n",
    "    out=average(rollingWindow(a, win_size), -1)\n",
    "    out1=np.append(np.zeros(int(win_size/2)),out)\n",
    "    out2=out1[:-int(win_size/2)] #these two modiciations make the filter symetric\n",
    "    return out\n",
    "    \n",
    "import numpy as np\n",
    "def find_nearest_unsrt(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=detect_peaks(trans[1],mph=.12,mpd=5000,valley=True,threshold=-.1,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peakrange=10 #number of peaks after a given one, we use to try and look for patterns\n",
    "peaks=test[minpeak:maxpeak]\n",
    "fwhm=[]\n",
    "peaksize=[]\n",
    "peakf=[]\n",
    "peakdiffs=[[x for x in range(len(peaks))] for y in range(len(peaks))]\n",
    "for i in range(len(peaks)): #gets peak size, location, and FWHM\n",
    "    psize=trans[1,peaks[i]]\n",
    "    pf=trans[0,peaks[i]]\n",
    "    neghalf=find_nearest_unsrt(trans[1,peaks[i]-5000:peaks[i]],psize/2)\n",
    "    poshalf=find_nearest_unsrt(trans[1,peaks[i]:peaks[i]+5000],psize/2)\n",
    "    fwhmlocal=abs(trans[0,poshalf]-trans[0,neghalf])\n",
    "    fwhm.append(fwhmlocal)\n",
    "    peaksize.append(psize)\n",
    "    peakf.append(pf)\n",
    "    peakdiffs[i][:]=peaks-peaks[i]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
